{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b68e67d2-8807-47f6-8410-2a00cfa243aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    # accuracy\n",
    "    def accuracy(self, confusion_matrix):\n",
    "        \n",
    "        matrix = confusion_matrix\n",
    "        len_matrix = len(matrix)\n",
    "        total_sum = np.sum(matrix)\n",
    "        true_sum = 0\n",
    "            \n",
    "        for i in range(len_matrix):\n",
    "            for j in range(len_matrix):\n",
    "                if i == j:\n",
    "                    true_sum += matrix[i][j]\n",
    "        accuracy = true_sum / total_sum\n",
    "        return accuracy\n",
    "        \n",
    "     #error   \n",
    "    def error(self, confusion_matrix):\n",
    "        accuracy = self.accuracy(confusion_matrix)\n",
    "        error = 1 - accuracy\n",
    "        return error\n",
    "\n",
    "    # precision\n",
    "    def precision(self, confusion_matrix):\n",
    "        matrix = confusion_matrix\n",
    "        precision = []\n",
    "        len_matrix = len(matrix)\n",
    "\n",
    "        for i in range(len_matrix):\n",
    "            true_positive = matrix[i][i]\n",
    "            false_positive = np.sum(matrix[:,i]) - true_positive\n",
    "            precision.append(true_positive / (true_positive + false_positive))\n",
    "\n",
    "        return precision\n",
    "\n",
    "    \n",
    "    # recall\n",
    "    def recall(self, confusion_matrix):\n",
    "        matrix = confusion_matrix\n",
    "        recall = []\n",
    "        len_matrix = len(matrix)\n",
    "\n",
    "        for i in range(len_matrix):\n",
    "            true_positive = matrix[i][i]\n",
    "            false_negative = np.sum(matrix[i,:]) - true_positive\n",
    "            recall.append(true_positive / (true_positive + false_negative))\n",
    "\n",
    "        return recall\n",
    "\n",
    "    # F_beta_score\n",
    "    def f_beta_score_cal(self, precision, recall, beta):\n",
    "        f_beta_score = []\n",
    "\n",
    "        for i in range(len(precision)):\n",
    "            f_beta_score_i = ((1 + beta**2) * precision[i] * recall[i]) / ((beta ** 2) * precision[i] + recall[i])\n",
    "            f_beta_score.append(f_beta_score_i)\n",
    "            \n",
    "        return f_beta_score\n",
    "        \n",
    "    def f_beta_score(self, confusion_matrix, beta=1):\n",
    "        precision = self.precision(confusion_matrix)\n",
    "        recall = self.recall(confusion_matrix)\n",
    "            \n",
    "        return f\"F{beta} Score: {self.f_beta_score_cal(precision=precision, recall=recall, beta=beta)}\"\n",
    "\n",
    "    # support\n",
    "    def support(self, confusion_matrix):\n",
    "        matrix = confusion_matrix\n",
    "        len_matrix = len(matrix)\n",
    "        support=[]\n",
    "        for i in range(len_matrix):\n",
    "            support_i = np.sum(matrix[i,:])\n",
    "            support.append(support_i)\n",
    "            \n",
    "        return support\n",
    "\n",
    "    # micro F1\n",
    "    def micro_f1(self, confusion_matrix):\n",
    "        beta = 1\n",
    "        matrix = confusion_matrix\n",
    "        true_positive = []\n",
    "        false_positive = []\n",
    "        false_negative = []\n",
    "        for  i in range(len(matrix)):\n",
    "            true_positive_i = matrix[i][i]\n",
    "            false_positive_i = np.sum(matrix[:,i]) - true_positive_i\n",
    "            false_negative_i = np.sum(matrix[i,:]) - true_positive_i\n",
    "            \n",
    "            true_positive.append(true_positive_i)\n",
    "            false_positive.append(false_positive_i)\n",
    "            false_negative.append(false_negative_i)\n",
    "\n",
    "        t_p = sum(true_positive)\n",
    "        f_p = sum(false_positive)\n",
    "        f_n = sum(false_negative)\n",
    "        \n",
    "        micro_precision = t_p/(t_p + f_p)\n",
    "        \n",
    "        micro_recall = t_p/(t_p + f_n)\n",
    "\n",
    "        micro_f1_ = ((1 + beta**2) * micro_precision * micro_recall) / ((beta ** 2) * micro_precision + micro_recall)\n",
    "        return micro_f1_\n",
    "\n",
    "    # macro F1\n",
    "    def macro_f1(self, confusion_matrix):\n",
    "        beta = 1\n",
    "        precision = self.precision(confusion_matrix)\n",
    "        recall = self.recall(confusion_matrix)\n",
    "\n",
    "         \n",
    "        macro_precision = np.sum(precision) / len(precision)\n",
    "        macro_recall = np.sum(recall) / len(recall) \n",
    "\n",
    "        macro_f1 = ((1 + beta**2) * macro_precision * macro_recall) / ((beta ** 2) * macro_precision + macro_recall)\n",
    "        return macro_f1\n",
    "        \n",
    "    # weighted F1\n",
    "    def weighted_f1_score(self, confusion_matrix):\n",
    "        beta = 1\n",
    "        precision = self.precision(confusion_matrix)\n",
    "        recall = self.recall(confusion_matrix)\n",
    "\n",
    "        matrix = confusion_matrix\n",
    "        weighted_precision = [] \n",
    "        weighted_recall = []\n",
    "        for i in range(len(matrix)):\n",
    "            \n",
    "            weighted_precision_i = (precision[i] * np.sum(matrix[:,i]))\n",
    "            weighted_recall_i = (recall[i] * np.sum(matrix[i,:])) \n",
    "            \n",
    "            weighted_precision.append(weighted_precision_i)\n",
    "            weighted_recall.append(weighted_recall_i)\n",
    "        w_p = sum(weighted_precision) / np.sum(matrix)\n",
    "        w_r = sum(weighted_recall) / np.sum(matrix)\n",
    "        weighted_f1 =  ((1 + beta**2) * w_p * w_r) / ((beta ** 2) * w_p + w_r)\n",
    "\n",
    "        return weighted_f1\n",
    "    # cohens_kappa\n",
    "    def cohens_kappa(self):\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8afc89-f2a3-449f-90e4-b64e54620fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# confusion_matrix\n",
    "confusion_matrix = np.array([[34, 13, 5],\n",
    "                             [0, 52, 0],\n",
    "                             [13,0, 33]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a19d53-ff20-4477-bfce-1eb4e6d61ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae12d71d-d2d5-40b0-b699-bac037501e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7933333333333333\n",
      "Error: 0.20666666666666667\n",
      "Precision: [0.723404255319149, 0.8, 0.868421052631579]\n",
      "Recall: [0.6538461538461539, 1.0, 0.717391304347826]\n",
      "F1 Score: [0.6868686868686869, 0.888888888888889, 0.7857142857142858]\n",
      "F0.5 Score: [0.7083333333333333, 0.8333333333333334, 0.8333333333333333]\n",
      "F2 Score: [0.6666666666666666, 0.9523809523809523, 0.7432432432432431]\n",
      "Support: [52, 52, 46]\n",
      "Micro F1 Score: 0.7933333333333333\n",
      "Macro F1 Score: 0.7938289628796671\n",
      "Weighted F1 Score: 0.7933333333333333\n",
      "Cohens Kappa: None\n"
     ]
    }
   ],
   "source": [
    "# Call the accuracy method\n",
    "accuracy = metrics.accuracy(confusion_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Call the error method\n",
    "error = metrics.error(confusion_matrix)\n",
    "print(\"Error:\", error)\n",
    "\n",
    "# Call the precision method\n",
    "precision = metrics.precision(confusion_matrix)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Call the recall method\n",
    "recall = metrics.recall(confusion_matrix)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Call the F1 score method\n",
    "f1_score = metrics.f_beta_score(confusion_matrix)\n",
    "print(f1_score)\n",
    "# Call the F1 score method\n",
    "f0_5_score = metrics.f_beta_score(confusion_matrix, beta=0.5)\n",
    "print(f0_5_score)\n",
    "# Call the F1 score method\n",
    "f2_score = metrics.f_beta_score(confusion_matrix,beta=2)\n",
    "print(f2_score)\n",
    "\n",
    "# Call the support method\n",
    "support = metrics.support(confusion_matrix)\n",
    "print(\"Support:\", support)\n",
    "\n",
    "# Call the micro F1 method\n",
    "micro_f1 = metrics.micro_f1(confusion_matrix)\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Call the macro F1 method\n",
    "macro_f1 = metrics.macro_f1(confusion_matrix)\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Call the weighted F1 score method\n",
    "weighted_f1_score = metrics.weighted_f1_score(confusion_matrix)\n",
    "print(\"Weighted F1 Score:\", weighted_f1_score)\n",
    "\n",
    "# Call the Cohens kappa method\n",
    "cohens_kappa = metrics.cohens_kappa()\n",
    "print(\"Cohens Kappa:\", cohens_kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d075fb-f35e-48c8-aafd-db6ee706a2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
