{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "468d1c1a-a165-477a-86e5-7faf3a7d0446",
   "metadata": {},
   "source": [
    "# Classification Evaluation Metrics\n",
    "* Confusion Matrix\n",
    "* Accuracy\n",
    "* Error\n",
    "* Precision\n",
    "* Recall\n",
    "* F-beta Score\n",
    "* Support\n",
    "* Micro F1\n",
    "* Macro F1\n",
    "* Weighted Average\n",
    "* Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9554f7f6-623d-4271-9eee-0ad892a41876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9358f1-f7f7-46af-b481-cc3d5a42d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    # confusion matrix\n",
    "    def confsion_matirx(self, y_test, y_pred):\n",
    "       \n",
    "        counts = {unique_val: {'tp': 0, 'fp': {other_val: 0 for other_val in y_test.unique() if other_val != unique_val}} for unique_val in y_test.unique()}\n",
    "\n",
    "        for true_label, pred_label in zip(y_test, y_pred):\n",
    "            if true_label == pred_label:\n",
    "                counts[true_label]['tp'] += 1\n",
    "            else:\n",
    "                counts[true_label]['fp'][pred_label] += 1\n",
    "                \n",
    "        num_class = len(counts)\n",
    "        \n",
    "        matrix = np.zeros((num_class, num_class), dtype=int)\n",
    "        \n",
    "        for i , true_label in enumerate(counts):\n",
    "            for j , pred_label in enumerate(counts):\n",
    "                if i == j:\n",
    "                    matrix[i][j] = counts[true_label]['tp']\n",
    "                else:\n",
    "                    matrix[i][j] = counts[true_label]['fp'].get(pred_label)\n",
    "        return matrix\n",
    "\n",
    "    # accuracy\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        \n",
    "        matrix = self.confusion_matrix(y_true, y_pred)\n",
    "        len_matrix = len(matrix)\n",
    "        total_sum = np.sum(matrix)\n",
    "        true_sum = 0\n",
    "            \n",
    "        for i in range(len_matrix):\n",
    "            for j in range(len_matrix):\n",
    "                if i == j:\n",
    "                    true_sum += matrix[i][j]\n",
    "        accuracy = true_sum / total_sum\n",
    "        return accuracy\n",
    "        \n",
    "     #error   \n",
    "    def error(self, y_true, y_pred):\n",
    "        accuracy = self.accuracy(y_true, y_pred)\n",
    "        error = 1 - accuracy\n",
    "        return error\n",
    "\n",
    "    # precision\n",
    "    def precision(self, y_true, y_pred):\n",
    "        matrix = self.confusion_matrix(y_true, y_pred)\n",
    "        precision = []\n",
    "        len_matrix = len(matrix)\n",
    "\n",
    "        for i in range(len_matrix):\n",
    "            true_positive = matrix[i][i]\n",
    "            false_positive = np.sum(matrix[:,i]) - true_positives\n",
    "            precision.append(true_positive / (true_positve + false_positive))\n",
    "\n",
    "        return precision\n",
    "\n",
    "    \n",
    "    # recall\n",
    "    def recall(self, y_true, y_pred):\n",
    "        matrix = self.confusion_matrix(y_true, y_pred)\n",
    "        recall = []\n",
    "        len_matrix = len(matrix)\n",
    "\n",
    "        for i in range(len_matrix):\n",
    "            true_positive = matrix[i][i]\n",
    "            false_negative = np.sum(matrix[i,:]) - true_positives\n",
    "            recall.append(true_positive / (true_positve + false_negative))\n",
    "\n",
    "        return recall\n",
    "\n",
    "    # F_beta_score\n",
    "    def f_beta_score_cal(precision, recall, beta):\n",
    "        f_beta_score = []\n",
    "\n",
    "        for i in range(len(precision)):\n",
    "            f_beta_score = ((1 + beta**2) * precision[i] * recall[i]) / ((beta ** 2) * precision[i] + recall[i])\n",
    "            f_beta_score.append(f_beta_score)\n",
    "        return f_beta_score\n",
    "        \n",
    "    def f_beta_score(self, y_true, y_pred, beta=1):\n",
    "        precision = self.precision(y_true, y_pred)\n",
    "        recall = self.recall(y_true, y_pred)\n",
    "            \n",
    "        return f\"F{beta} Score: {f_beta_score_cal(precision=precisoin, recall=recall, beta=beta)}\"\n",
    "\n",
    "    # support\n",
    "    def support(self, y_true, y_pred):\n",
    "        matrix = self.confusion_matrix(y_true, y_pred)\n",
    "        len_matrix = len(matrix)\n",
    "        support=[]\n",
    "        for i in range(len_matrix):\n",
    "            support_i = np.sum(matrix[i,:])\n",
    "            support.append(support_i)\n",
    "            \n",
    "        return support\n",
    "\n",
    "    # micro F1\n",
    "    def micro_f1(self, y_true, y_pred):\n",
    "        matrix = self.confusion_matrix(y_true, y_pred)\n",
    "        micro_precision = []\n",
    "        micro_recall = []\n",
    "\n",
    "        for  i in range(len(matirix)):\n",
    "            true_positive = matrix[i][i]\n",
    "            false_positive = np.sum(matrix[:,i]) - true_positive\n",
    "            false_negative = np.sum(matrix[i,:]) - true_positive\n",
    "            micro_precision.append(true_positive/(true_positive - false_positive))\n",
    "            micro_recall.append(true_positive/(true_positive - false_negative))\n",
    "\n",
    "            micro_f1 = self.f_beta_score_cal(precison=micro_presion, recall=micro_presion, beta=1)\n",
    "            return micro_f1\n",
    "\n",
    "    # macro F1\n",
    "    def macro_f1(self, y_true, y_pred):\n",
    "        precision = self.precision(y_true, y_pred)\n",
    "        recall = self.recall(y_true, y_pred)\n",
    "\n",
    "        macro_precision = np.sum(precision) / len(precision)\n",
    "        macro_recall = np.sum(recall) / len(recall) \n",
    "\n",
    "        macro_f1 = self.f_beta_score_cal(precision=macro_precision, recall=macro_precision, beta=1)\n",
    "        return macro_f1\n",
    "        \n",
    "    # weighted F1\n",
    "    def weighted_f1_score():\n",
    "        precision = self.precision(y_true, y_pred)\n",
    "        recall = self.recall(y_true, y_pred)\n",
    "\n",
    "        matrix = self.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        for i in range(len(matrix)):\n",
    "            \n",
    "            weighted_precision = (precision[i] * np.sum(matrix[:,i])) / np.sum(matrix)\n",
    "            weighted_recall = (recall[i] * np.sum(matrix[i,:])) / np.sum(matrix)\n",
    "\n",
    "        weighted_f1 = self.f_beta_score_cal(precision=weighted_precision, recall=weighted_recall, beta=1)\n",
    "\n",
    "        return weighted_f1\n",
    "    # cohens_kappa\n",
    "    def cohens_kappa():\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a358bd5-b4b5-4da4-9389-d02496e12b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
